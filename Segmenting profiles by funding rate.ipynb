{
 "metadata": {
  "name": "",
  "signature": "sha256:200871090d1022109dca87f2db11e7c5cb9e38f59fce28ae458d797c0adb986a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Can we predict the funding pattern of any given profile?\n",
      "\n",
      "We have data from a Kickstarter-like company. Profiles list different amounts at which to be funded. Nearly all the profiles end up getting funded. All the profiles in this dataset have been funded. Taken from a subset of the data, it looks like this:\n",
      "\n",
      "[insert graph]\n",
      "\n",
      "If we can find out various attributes that predict a funding pattern, we can optimize for these various attributes so that profiles can be funded more quickly!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So, we want to see if there are different funding patterns amongst the different rates at which profiles get funded. If there are, we can try to predict which rate a certain profile fits into, and what factors lead to certain rates."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import psycopg2\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import getpass\n",
      "from numpy import log\n",
      "\n",
      "pd.options.display.mpl_style = 'default'\n",
      "\n",
      "conn = psycopg2.connect(dbname=\"watsi\", host=\"localhost\", user=\"aok1425\", password=getpass.getpass())\n",
      "cur = conn.cursor()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Pulling the data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is the function to pull the data for a certain profile.\n",
      "\n",
      "Note that if the data is abnormal, the function returns a blank table. Data can be abnormal in a few ways:\n",
      "- adding up all the donations results in a figure different from the total amount, by at least 10%\n",
      "- some donations were done before the profile was posted online\n",
      "- I'm ignoring those profiles that were funded really quickly. The histogram of how quickly profiles are funded is a Poisson distribution [insert graph?]. 25% of the profiles were funded in less than 37.84 hours. Thus, I only want to find out about the other 75%. [show that the 25% has same characteristics as the 75%?]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pull_SQL_table(patient_id):    \n",
      "\tquery = \"\"\"\n",
      "\t\tselect donor_id, patient, cum_amt::int, hours_after_posted, num\n",
      "\t\tfrom (\n",
      "\t\tselect *, bool_and(hours_after_posted >= 0) over (partition by patient) as normal_hours_after_posted, max(cum_amt) over (partition by patient) as max_amt, count(*) over (partition by patient) as \"num\"\n",
      "\t\tfrom (\n",
      "\t\tselect donor_id, patient, sum(donation_amt) over (partition by patient order by time_of_donation) as cum_amt, total_amt, extract(epoch from (time_of_donation - min(time_of_donation) over (partition by patient)))/3600 as hours_after_posted, extract(epoch from hrs_to_completion)/3600 as hrs_to_completion\n",
      "\t\tfrom (\n",
      "\t\tselect donor_id, p.id as patient, c.donation_amount * .01 as \"donation_amt\", p.target_amount * .01 as total_amt, c.created_at - p.created_at as \"time_of_donation\", max(c.created_at - p.created_at) over (partition by p.id) as \"hrs_to_completion\"\n",
      "\t\tfrom contributions as c join profiles as p\n",
      "\t\ton (c.contributable_id = p.id)\n",
      "\t\twhere contributable_id = {}) table1) table2) table3\n",
      "\t\twhere @(max_amt-total_amt)/total_amt < 0.1 and normal_hours_after_posted = true and hrs_to_completion > 37.84\n",
      "\t\torder by patient, cum_amt;\"\"\".format(patient_id)\n",
      "    \n",
      "\tcur.execute(query)\n",
      "\tfig = pd.DataFrame(cur.fetchall(), columns = [desc[0] for desc in cur.description])\n",
      "\n",
      "\treturn fig\n",
      "\n",
      "def pull_SQL_into_Pandas(query):\n",
      "\t\"\"\"Takes a query, and outputs a DataFrame from it.\"\"\"\n",
      "\tcur.execute(query)\n",
      "\tfig = pd.DataFrame(cur.fetchall(), columns = [desc[0] for desc in cur.description])\n",
      "\n",
      "\treturn fig"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Applying the models for each profile\n",
      "For each table, I will apply 3 different models to the data: linear, logarithmic, and exponential. Then, I will find the error for each model for each profile."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def predict_exp(x, y):\n",
      "\t\"\"\"Input a DataFrame and get a Series of predict values.\"\"\"\n",
      "\tydiff = y.tail(1).values[0] - y.head(1).values[0]\n",
      "\txdiff = x.tail(1).values[0] - x.head(1).values[0]\n",
      "\n",
      "\tz = ydiff**(1/xdiff)\n",
      "\treturn z**x + y.head(1).values[0]\n",
      "\n",
      "def predict_lin(x, y):\n",
      "\tm = (y.tail(1).values[0] - y.head(1).values[0])/(x.tail(1).values[0] - x.head(1).values[0])\n",
      "\n",
      "\treturn m*x + y.head(1).values[0]\n",
      "\n",
      "def predict_log_e(x, y):\n",
      "\t\"\"\"B/c first value of log(x) is always -inf, ignore the first element when scoring?\"\"\"\n",
      "\tydiff = y.tail(1).values[0] - y.head(1).values[0]\n",
      "\txdiff = x.tail(1).values[0] - x.head(1).values[0]\n",
      "\tb = ydiff / (log(xdiff))\n",
      "\n",
      "\treturn b*log(x) + y.head(1).values[0]\n",
      "\n",
      "def plot_predictor(patient_id):\n",
      "\t\"\"\"Makes graph showing the 3 models and the ground truth for a patient.\"\"\"\n",
      "\tfig = pull_SQL_table(patient_id)\n",
      "\tfig['lin_pred'] = predict_lin(fig.hours_after_posted, fig.cum_amt)\n",
      "\tfig['exp_pred'] = predict_exp(fig.hours_after_posted, fig.cum_amt)\n",
      "\tfig['log_pred'] = predict_log_e(fig.hours_after_posted, fig.cum_amt)\n",
      "\n",
      "\tfig.plot(x='hours_after_posted', y='cum_amt')\n",
      "\tfig.plot(x='hours_after_posted', y='lin_pred')\n",
      "\tfig.plot(x='hours_after_posted', y='exp_pred')\n",
      "\tfig.plot(x='hours_after_posted', y='log_pred')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pull_error_table():\n",
      "\tquery = \"\"\"\n",
      "        select patient, count\n",
      "        from(\n",
      "        select p.id as patient, count(*) as count, @((sum(c.donation_amount)-p.target_amount::float)/p.target_amount) as diff_pct, p.target_amount * .01 as total_amt, extract(epoch from min(c.created_at - p.created_at))/3600 as \"min_time_of_donation\", extract(epoch from max(c.created_at - p.created_at))/3600 as \"hrs_to_completion\"\n",
      "        from contributions as c join profiles as p\n",
      "        on (c.contributable_id = p.id)\n",
      "        group by p.id\n",
      "        order by diff_pct desc) table1\n",
      "        where diff_pct < 0.1 and min_time_of_donation > 0 and hrs_to_completion > 37.84 and count > 3;\"\"\"\n",
      "\n",
      "\tcur.execute(query)\n",
      "\tfig = pd.DataFrame(cur.fetchall(), columns = [desc[0] for desc in cur.description])\n",
      "    \n",
      "\treturn fig\n",
      "\n",
      "from sklearn.metrics import explained_variance_score\n",
      "\n",
      "def calculate_model_errors(patient_id):\n",
      "    fig = pull_SQL_table(patient_id)\n",
      "    x = fig.hours_after_posted\n",
      "    y = fig.cum_amt\n",
      "    \n",
      "    exp = predict_exp(x,y)\n",
      "    lin = predict_lin(x,y)\n",
      "    log = predict_log_e(x,y)\n",
      "    \n",
      "    return explained_variance_score(y, exp), explained_variance_score(y[1:], log[1:]), explained_variance_score(y, lin)\n",
      "\n",
      "df = pull_error_table()\n",
      "df['exp_error'], df['log_error'], df['lin_error'] = zip(*df.patient.map(calculate_model_errors))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_pickle('./saved_tables/error_table.pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Evaluating the models for each profile"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import kmeans\n",
      "km = kmeans.KMeans(max_iters=7, tries=15)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import preprocessing\n",
      "df_scaled = preprocessing.scale(df.ix[:,'exp_error':'lin_error'])\n",
      "\n",
      "km.fit(df_scaled) # much better!\n",
      "#km.plotj(7) # I cld choose 3 or 4 centroids"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "How many centroids? 3\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Running K-means 15 times, moving the 3 centroids a max of 7 on each try...\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "                                    centroid position how many for each  \\\n",
        "11  [[[-0.400461912483, -0.0809048296118, 0.606102...   [762, 939, 333]   \n",
        "2   [[[0.789202758401, 0.0412468096746, 0.09001117...   [915, 336, 783]   \n",
        "6   [[[-0.381985490834, -0.0771895209349, 0.605149...   [783, 318, 933]   \n",
        "0   [[[-1.23909731039, 0.0488254129932, -1.6519077...  [342, 1017, 675]   \n",
        "12  [[[-0.480882694711, 0.0552058954539, 0.5940818...  [678, 1011, 345]   \n",
        "\n",
        "           J  \n",
        "11  1.794454  \n",
        "2   1.794585  \n",
        "6   1.795196  \n",
        "0   1.797317  \n",
        "12  1.797533  \n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# !!! when i put in kmeans_categories, that contains entries for ALL pts. i need to align this with the patients i actually do have, as i've \n",
      "# filtered some of them out.\n",
      "\n",
      "# i need to do the same with log_reg_table further below\n",
      "\n",
      "df['kmeans_categories'] = km.find_centroid_for_each()\n",
      "df['kmeans_categories'] = df['kmeans_categories'].map({0:'lin_error', 1:'exp_error', 2:'log_error'})\n",
      "df['best_model_categories'] = df.ix[:,'exp_error':'lin_error'].idxmax(axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_pickle('./saved_tables/predicted_curves_for_each_profile.pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There is a discrepancy between what KMeans predicts and which of the three models has the lowest error rate."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "discrep = len(df.ix[:,-2:][df.kmeans_categories != df.best_model_categories])/float(len(df))\n",
      "print '{:.1%} of the entries have a discrepancy between what KMeans predicts and which of the 3 models has the lowest error rate'.format(discrep)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "28.6% of the entries have a discrepancy between what KMeans predicts and which of the 3 models has the lowest error rate\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To find the count of the number of profiles for which that model was the best:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['best_model_categories'].groupby(df['best_model_categories']).count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "best_model_categories\n",
        "exp_error                292\n",
        "lin_error                316\n",
        "log_error                 70\n",
        "Name: best_model_categories, dtype: int64"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Can we predict which of the funding curves any one profile might have?\n",
      "Let's start by collecting all the attributes, or features, we think might be relevant to whichever funding curve a profile might have.\n",
      "\n",
      "Feature 1: how many other fundable profiles are there at the time of a profile's first donation?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "temp_table = pull_SQL_into_Pandas(\n",
      "    \"\"\"\n",
      "    select table2.contributable_id as t2id, count(*) as other_fundable_pts, max(table2.pct_of_first_donation) as pct_of_first_donation, max(table2.funding_amt) as funding_amt\n",
      "    from\n",
      "    (select *\n",
      "    from (select c.contributable_id, max(p.created_at) as posted_date, min(c.created_at) as first_donation, max(p.funded_at) as funded_date, min(c.donation_amount)/max(p.target_amount)::float as pct_of_first_donation, max(p.target_amount) as funding_amt\n",
      "    from contributions as c join profiles as p\n",
      "    on c.contributable_id = p.id\n",
      "    group by c.contributable_id) table1\n",
      "    where posted_date < first_donation /* there are 42 of these */ and funded_date is not null /* 33 of these */) table2\n",
      "    ,\n",
      "    (select *\n",
      "    from (select c.contributable_id, max(p.created_at) as posted_date, min(c.created_at) as first_donation, max(p.funded_at) as funded_date\n",
      "    from contributions as c join profiles as p\n",
      "    on c.contributable_id = p.id\n",
      "    group by c.contributable_id) table3\n",
      "    where posted_date < first_donation /* there are 42 of these */ and funded_date is not null /* 33 of these */) table4\n",
      "\n",
      "    where table2.first_donation < table4.funded_date and table2.first_donation > table4.posted_date\n",
      "    group by table2.contributable_id\n",
      "    order by table2.contributable_id;\"\"\")\n",
      "\n",
      "log_reg_table = pd.merge(df, temp_table, left_on='patient', right_on='t2id').ix[:,['patient', 'other_fundable_pts', 'pct_of_first_donation', 'funding_amt', 'kmeans_categories', 'best_model_categories']].sort('patient')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "log_reg_table = pd.read_pickle('./saved_tables/log_reg_table.pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Evaluating the models"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import preprocessing\n",
      "\n",
      "X_scaled = preprocessing.scale(log_reg_table.ix[:,'other_fundable_pts':'funding_amt'])\n",
      "y = log_reg_table.kmeans_categories\n",
      "y = log_reg_table.best_model_categories\n",
      "\n",
      "le = preprocessing.LabelEncoder()\n",
      "le.fit(y)\n",
      "\n",
      "y = le.transform(y)\n",
      "\n",
      "from sklearn import linear_model\n",
      "from sklearn import cross_validation\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "\n",
      "logistic = linear_model.LogisticRegression()\n",
      "logistic.fit(X_scaled, y)\n",
      "logistic.score(X_scaled, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "0.48525073746312686"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "clf = RandomForestClassifier(n_jobs=-1)\n",
      "clf.fit(X_scaled, y)\n",
      "clf.score(X_scaled, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "0.87315634218289084"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cross_val_score(clf, X_scaled, y, cv=5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "array([ 0.51470588,  0.49264706,  0.53676471,  0.55555556,  0.51111111])"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cross_val_score(logistic, X_scaled, y, cv=5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "array([ 0.47058824,  0.48529412,  0.47794118,  0.48888889,  0.46666667])"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Summary/Conclusion\n",
      "So, what have we done?\n",
      "\n",
      "We categorized the funding pattern of each profile into one of 3 patterns.\n",
      "\n",
      "We did K-means clustering to find out, after fitting each profile to these patterns, how many categories the funding patterns fall into. Either 3 or 4 seem like a reasonable conclusion. [insert graph]\n",
      "\n",
      "What is the fourth pattern, if not one of the 3 models we made? Through anecdotal evidence, I think it's a step-wise function. [insert graph]\n",
      "\n",
      "Then, we tried to predict which one of the 3 patterns any given funding would fall into. We made informed guesses that these things were relevant:\n",
      "* amount of first donation\n",
      "* amount to fully fund profile\n",
      "* number of profiles available to fund at the time of the first donation\n",
      "\n",
      "We used Logistic Regression and Random Forests methods to make predictions, and got uniformly bad results, around 50%."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Next steps\n",
      "Machine learning depends heavily on the quality of its features. The better the features we can create or extract, the more accurate we can get our algorithm."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}